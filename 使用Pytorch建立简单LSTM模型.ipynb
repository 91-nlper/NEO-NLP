{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 简单的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\\begin{bmatrix}\n",
    "\\overbrace{q_\\text{The}}^\\text{row vector} \\\\\n",
    "q_\\text{cow} \\\\\n",
    "q_\\text{jumped}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单词分开训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.8584, -0.4522, -0.2769]]),\n",
       " tensor([[ 1.2667, -0.1537,  1.6023]]),\n",
       " tensor([[0.5256, 0.6136, 0.4005]]),\n",
       " tensor([[-0.7552, -0.5332, -1.1395]]),\n",
       " tensor([[0.0900, 0.5821, 0.0626]])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch中的LSTM接受三维数据，如上图所示\n",
    "#第一维是序列本身即如果是句子则是单词个数，\n",
    "#第二维是mini-batch的个数，\n",
    "#第三维是单个词向量的维度\n",
    "lstm01 = nn.LSTM(3, 3)   # 输入三维数据，输出三维数据\n",
    "inputs01 = [torch.randn(1,3) for _ in range(5)]    # 模拟五个单词的句子，单词词向量维度是3\n",
    "inputs01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0343, -0.2791,  0.4836]]]),\n",
       " tensor([[[-1.1297,  1.4051,  1.8485]]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化隐藏层即 a[0], h[0]   LSTM有两条线贯穿始终\n",
    "hidden01 = (torch.randn(1,1,3), torch.randn(1, 1, 3))\n",
    "hidden01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2819,  0.2234, -0.1141]]], grad_fn=<StackBackward>)\n",
      "\n",
      "(tensor([[[ 0.2819,  0.2234, -0.1141]]], grad_fn=<StackBackward>), tensor([[[ 0.4250,  0.7577, -0.1533]]], grad_fn=<StackBackward>))\n",
      "---------------------------------\n",
      "tensor([[[0.1028, 0.2091, 0.0778]]], grad_fn=<StackBackward>)\n",
      "\n",
      "(tensor([[[0.1028, 0.2091, 0.0778]]], grad_fn=<StackBackward>), tensor([[[0.7733, 0.8781, 0.2533]]], grad_fn=<StackBackward>))\n",
      "---------------------------------\n",
      "tensor([[[ 0.3578,  0.3484, -0.1579]]], grad_fn=<StackBackward>)\n",
      "\n",
      "(tensor([[[ 0.3578,  0.3484, -0.1579]]], grad_fn=<StackBackward>), tensor([[[ 0.5042,  0.5998, -0.1813]]], grad_fn=<StackBackward>))\n",
      "---------------------------------\n",
      "tensor([[[0.1813, 0.1406, 0.0445]]], grad_fn=<StackBackward>)\n",
      "\n",
      "(tensor([[[0.1813, 0.1406, 0.0445]]], grad_fn=<StackBackward>), tensor([[[0.3372, 0.8399, 0.0912]]], grad_fn=<StackBackward>))\n",
      "---------------------------------\n",
      "tensor([[[0.1854, 0.4358, 0.0853]]], grad_fn=<StackBackward>)\n",
      "\n",
      "(tensor([[[0.1854, 0.4358, 0.0853]]], grad_fn=<StackBackward>), tensor([[[0.8274, 0.8868, 0.1335]]], grad_fn=<StackBackward>))\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in inputs01:\n",
    "    out01, hidden01 = lstm01(i.view(1, 1, -1), hidden01)\n",
    "    print(out01)\n",
    "    print()\n",
    "    print(hidden01)\n",
    "    print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单词合在一起训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-1.2982, -0.0629, -0.3089]]), tensor([[ 1.7893,  0.4237, -0.3040]]), tensor([[ 0.0031, -1.5194, -0.3608]]), tensor([[-0.1000, -1.0359, -0.3672]]), tensor([[ 1.0311, -1.4525,  0.4833]])]\n",
      "------------------------------------\n",
      "(tensor([[[0.9352, 0.0712, 1.6371]]]), tensor([[[1.3713, 1.2862, 0.2090]]]))\n",
      "------------------------------------\n",
      "tensor([[[-0.2333,  0.2044,  0.2867]],\n",
      "\n",
      "        [[-0.5073,  0.2041, -0.0039]],\n",
      "\n",
      "        [[-0.2558,  0.1444, -0.0689]],\n",
      "\n",
      "        [[-0.2057,  0.1001, -0.0840]],\n",
      "\n",
      "        [[-0.2546,  0.1072, -0.1950]]], grad_fn=<StackBackward>)\n",
      "\n",
      "(tensor([[[-0.2546,  0.1072, -0.1950]]], grad_fn=<StackBackward>), tensor([[[-0.4147,  0.1835, -0.2649]]], grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "lstm02 = nn.LSTM(3, 3)   # 输入三维数据，输出三维数据\n",
    "inputs02 = [torch.randn(1,3) for _ in range(5)]    # 模拟五个单词的句子，单词词向量维度是3\n",
    "print(inputs02)\n",
    "print(\"------------------------------------\")\n",
    "hidden02 = (torch.randn(1,1,3), torch.randn(1, 1, 3))\n",
    "print(hidden02)\n",
    "print(\"------------------------------------\")\n",
    "inputs02 = torch.cat(inputs02).view(len(inputs02), 1, -1)  # 修改序列长度维度为 5\n",
    "hidden02 = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))\n",
    "out02, hidden02 = lstm02(inputs02, hidden02)\n",
    "print(out02)\n",
    "print()\n",
    "print(hidden02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
